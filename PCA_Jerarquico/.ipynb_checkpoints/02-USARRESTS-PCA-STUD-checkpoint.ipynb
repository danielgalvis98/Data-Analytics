{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA con los datos de arrestos por estado en USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar una pequeña base de datos que describe la cantidad de arrestos en cada uno de los estados de USA.\n",
    "La unidad de estudio es entonces cada estado de USA, que se describen a partir de las siguientes variables:\n",
    "- State: nombre del estado en cuestión\n",
    "- Murder: cantidad de arrestos por asesinato\n",
    "- Assault: cantidad de arrestos por asalto\n",
    "- Rape: cantidad de arrestos por violación\n",
    "- UrbanPop: identifica el porcentaje de población urbana de cada estado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y entendimiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('02-ArrestosUSA.csv', na_values=\".\", sep=\";\")\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a cambiar la variable State, para que sea el índice de las instancias de cada fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(df.State)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"State\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el dataset esta completo, que los valores son todos numéricos.\n",
    "También podemos percibir que el número de asaltos es mucho más elevado que el de asesinatos, presentado además una desviación estándar bien importante con respecto a las otras variables numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, cuando calculamos las varianzas de las variables encontramos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable \"Assault\" es responsable por la mayoría de la varianza del dataset. Es el atributo que aportaría mayor información en caso de no normalizar los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyección sobre el espacio de representación de los componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "df_proyectado = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ajustado el objeto PCA a un dataset, este permite acceder a diferentes aspectos resultantes de la transformación:\n",
    "- **components_**: los ejes de los componentes principales en función de las variables originales. Como teníamos 64 variables, vamos a tener 64 PCs, cada uno con las cargas (*loadings*) correspondientes a cada variable original (64 variables originales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos los aportes de cada variable original a cada componente principal:\n",
    "- Podemos ver que el primer componente principal PC1 tiene una participación positiva muy importante de la segunda variable original, con un loading de 0.9952 asociado a \"Assault\". Esto se puede interpretar como que PC1 es casi que una copia de Assault; a mayores valores de Assault, mayor valor del PC1\n",
    "- El segundo PC esta sobretodo caracterizado por el aporte negativo de la tercera variable (UrbaPop); a mayor valor de UrbanPop, menor valor de PC2\n",
    "- PC3 se caracteriza por tener una carga importante asociada a la cuarta variable (Rape)\n",
    "- PC4 se caracteriza por tener una carga importante asociada a la primera variable (Murder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad en este primer intento cada PC esta asociado sobretodo a una de las variables originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **explained_variance_**: la varianza explicada por cada eje en las unidades originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **explained_variance_ratio_**: la proporción de la varianza explicada por cada eje, en porcentaje (la suma da 100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_exp=pca.explained_variance_ratio_ # varianza explicada por cada PC\n",
    "cum_var_exp = np.cumsum(var_exp) # varianza acumulada por los primeros n PCs\n",
    "var_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto PCA sirve además para pasar de la representación en las dimensiones originales a la de las dimensiones en el espacio de los componentes principales encontrados, a partir de su método transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPca = pca.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos gráficamente la cantidad de información correspondiente a cada componente principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.bar(range(len(var_exp)), var_exp, alpha=0.3333, align='center', label='Varianza explicada por cada PC', color = 'g')\n",
    "plt.step(range(len(cum_var_exp)), cum_var_exp, where='mid',label='Varianza explicada acumulada')\n",
    "plt.ylabel('Porcentaje de varianza explicada')\n",
    "plt.xlabel('Componentes principales')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que PC1 representa por sí solo el 96.5% de la información. Recordemos que este PC estaba asociado a la variable Assault, que era la que originalmente tenía la mayor proporción de información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad, el proceso que acabamos de realizar está viciado, en el sentido de que no normalizamos los datos, dándole más importancia a la variable con valores de mayor escala (Assault)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos entonces a corregir el proceso, estandarizando los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.fit(df)\n",
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "df_proyectado = pca.fit_transform(df_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ajustado el objeto PCA a un dataset, este permite acceder a diferentes aspectos resultantes de la transformación:\n",
    "- **components_**: los ejes de los componentes principales en función de las variables originales. Como teníamos 64 variables, vamos a tener 64 PCs, cada uno con las cargas (*loadings*) correspondientes a cada variable original (64 variables originales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos los aportes de cada variable original a cada componente principal:\n",
    "- PC1 tiene una participación positiva fuerte de las tres variables asociadas a los 3 tipos de crímenes, por lo que podemos interpretar esta nueva variable como un \"índice de criminalidad\".\n",
    "- PC2 esta sobretodo caracterizado por el aporte negativo importante de la tercera variable (UrbaPop); a mayor valor de UrbanPop, menor valor de PC2\n",
    "- PC3 se caracteriza por tener una carga importante asociada a Rape\n",
    "- PC4 se caracteriza por tener una carga importante asociada a Murder y Asalto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pca.explained_variance_ratio_[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que PC1 representa el 62% de la varianza y que PC2 el 24.7%. Entre estos dos componentes tenemos entonces el 86.7% de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_exp=pca.explained_variance_ratio_ # varianza explicada por cada PC\n",
    "cum_var_exp = np.cumsum(var_exp) # varianza acumulada por los primeros n PCs\n",
    "var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.bar(range(len(var_exp)), var_exp, alpha=0.3333, align='center', label='Varianza explicada por cada PC', color = 'g')\n",
    "plt.step(range(len(cum_var_exp)), cum_var_exp, where='mid',label='Varianza explicada acumulada')\n",
    "plt.ylabel('Porcentaje de varianza explicada')\n",
    "plt.xlabel('Componentes principales')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualicemos los datos proyectados sobre los dos primeros componentes principales, para entender mejor el dataset en su nueva representación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.scatter(df_proyectado[:, 0], df_proyectado[:, 1], alpha=0.5)\n",
    "plt.xlabel('PC1: índice de criminalidad')\n",
    "plt.ylabel('PC2: de mas urbano (valores negativos) a menos urbano (valores positivos)')\n",
    "for x,y,label in zip(df_proyectado[:, 0], df_proyectado[:, 1], df.index):\n",
    "    plt.annotate(label,\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver los puntos en el nuevo sistema de representación dado por los componentes principales.\n",
    "Creamos una función que permite plotear tanto los puntos de los datos como los loadings de las variables originales (tomada de https://stackoverflow.com/questions/39216897/plot-pca-loadings-and-loading-in-biplot-in-sklearn-like-rs-autoplot).\n",
    "Esto nos permitirá entender mejor la relación entre componentes principales y variables originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot(data, loadings, index1, index2, labels=None, point_labels=None):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    xs = data[:,index1]\n",
    "    ys = data[:,index2]\n",
    "    n=loadings.shape[0]\n",
    "    scalex = 1.0/(xs.max()- xs.min())\n",
    "    scaley = 1.0/(ys.max()- ys.min())\n",
    "    plt.scatter(xs*scalex,ys*scaley)\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, loadings[i,index1]*.8, loadings[i,index2]*.8,color='r',alpha=0.5)\n",
    "        if labels is None:\n",
    "            plt.text(loadings[i,index1]*.85, loadings[i,index2]*.85, \"Var\"+str(i+1), color='g', ha='center', va='center')\n",
    "        else:\n",
    "            plt.text(loadings[i,index1]*.85, loadings[i,index2]*.85, labels[i], color='g', ha='center', va='center')\n",
    "    for x,y,label in zip(xs*scalex, ys*scaley, point_labels):\n",
    "        plt.annotate(label,\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    plt.xlabel(\"PC{}\".format(index1+1))\n",
    "    plt.ylabel(\"PC{}\".format(index2+1))\n",
    "    plt.grid() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como nos va con los primeros dos componentes principales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biplot(df_proyectado, pca.components_, 0, 1, df.columns, df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biplot(dataPca, pca.components_, 0, 2, df.columns, df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
